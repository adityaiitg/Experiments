{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vagb-CsV0J6h"
      },
      "outputs": [],
      "source": [
        "# !pip install tensorflow==1.15\n",
        "# !pip install numpy==1.19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "S9bYW1Mj4mav"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZ9CVueWSkxn",
        "outputId": "1e7f496d-73d9-4f59-d8df-7b36f7df9aba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-b23073eb924e>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib import rnn\n",
        "\n",
        "# Import MNIST data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kyGTAyQmzoU7",
        "outputId": "ced3ed38-a5ac-4729-f938-3e3ea3daa167"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "V6jDRs7NS7xw"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflow==1.15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iCuSt2hBSkxo"
      },
      "outputs": [],
      "source": [
        "# Training Parameters\n",
        "learning_rate = 0.001\n",
        "training_steps = 10000\n",
        "batch_size = 256\n",
        "display_step = 200\n",
        "\n",
        "# Network Parameters\n",
        "num_input = 28 # MNIST data input (img shape: 28*28)\n",
        "timesteps = 28 # timesteps\n",
        "num_hidden = 128 # hidden layer num of features\n",
        "num_classes = 10 # MNIST total classes (0-9 digits)\n",
        "\n",
        "# tf Graph input\n",
        "X = tf.placeholder(\"float\", [None, timesteps,num_input])\n",
        "Y = tf.placeholder(\"float\", [None, num_classes])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "2YU-YiDTSkxp"
      },
      "outputs": [],
      "source": [
        "# Define weights\n",
        "weights = {\n",
        "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
        "}\n",
        "biases = {\n",
        "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "odhg6UXgSkxq"
      },
      "outputs": [],
      "source": [
        "def RNN(x, weights, biases):\n",
        "  x = tf.unstack(x, timesteps, 1)\n",
        "\n",
        "    # Define a lstm cell with tensorflow\n",
        "  lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias = 1)\n",
        "\n",
        "  outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
        "\n",
        "    # Linear activation, using rnn inner loop last output\n",
        "  return tf.matmul(outputs[-1], weights['out']) + biases['out']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FEQ3qHCWSkxq",
        "outputId": "e345edc9-91e1-447a-9e22-0d8cf2f95907"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-8-90e3bcaa70f8>:5: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-8-90e3bcaa70f8>:7: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        }
      ],
      "source": [
        "logits = RNN(X, weights, biases)\n",
        "prediction = tf.nn.softmax(logits)\n",
        "\n",
        "# Define loss and optimizer\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate,name = 'Adam')\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "# Evaluate model (with test logits, for dropout to be disabled)\n",
        "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# Initialize the variables (i.e. assign their default value)\n",
        "init = tf.global_variables_initializer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SoDxAtneXo9n"
      },
      "outputs": [],
      "source": [
        "# batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "# batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
        "# batch_x.shape\n",
        "#  tf.transpose(batch_x,perm = [1,0,2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqtHqES_Skxr",
        "outputId": "ba863040-6c77-4a68-d049-601d99e3f0f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1, Minibatch Loss= 2.6455, Training Accuracy= 0.094\n",
            "Step 200, Minibatch Loss= 0.2095, Training Accuracy= 0.930\n",
            "Step 400, Minibatch Loss= 0.1033, Training Accuracy= 0.957\n",
            "Step 600, Minibatch Loss= 0.0883, Training Accuracy= 0.973\n",
            "Step 800, Minibatch Loss= 0.0751, Training Accuracy= 0.965\n",
            "Step 1000, Minibatch Loss= 0.0345, Training Accuracy= 0.988\n",
            "Step 1200, Minibatch Loss= 0.0547, Training Accuracy= 0.977\n",
            "Step 1400, Minibatch Loss= 0.0654, Training Accuracy= 0.984\n",
            "Step 1600, Minibatch Loss= 0.0398, Training Accuracy= 0.992\n",
            "Step 1800, Minibatch Loss= 0.0233, Training Accuracy= 0.992\n",
            "Step 2000, Minibatch Loss= 0.0216, Training Accuracy= 0.996\n",
            "Step 2200, Minibatch Loss= 0.0179, Training Accuracy= 0.996\n",
            "Step 2400, Minibatch Loss= 0.0309, Training Accuracy= 0.996\n",
            "Step 2600, Minibatch Loss= 0.0063, Training Accuracy= 1.000\n",
            "Step 2800, Minibatch Loss= 0.0364, Training Accuracy= 0.988\n",
            "Step 3000, Minibatch Loss= 0.0309, Training Accuracy= 0.996\n",
            "Step 3200, Minibatch Loss= 0.0196, Training Accuracy= 0.996\n",
            "Step 3400, Minibatch Loss= 0.0227, Training Accuracy= 0.992\n",
            "Step 3600, Minibatch Loss= 0.0051, Training Accuracy= 1.000\n",
            "Step 3800, Minibatch Loss= 0.0116, Training Accuracy= 0.996\n",
            "Step 4000, Minibatch Loss= 0.0197, Training Accuracy= 0.992\n",
            "Step 4200, Minibatch Loss= 0.0041, Training Accuracy= 1.000\n",
            "Step 4400, Minibatch Loss= 0.0047, Training Accuracy= 0.996\n",
            "Step 4600, Minibatch Loss= 0.0020, Training Accuracy= 1.000\n",
            "Step 4800, Minibatch Loss= 0.0026, Training Accuracy= 1.000\n",
            "Step 5000, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
            "Step 5200, Minibatch Loss= 0.0172, Training Accuracy= 0.996\n",
            "Step 5400, Minibatch Loss= 0.0026, Training Accuracy= 1.000\n",
            "Step 5600, Minibatch Loss= 0.0011, Training Accuracy= 1.000\n",
            "Step 5800, Minibatch Loss= 0.0038, Training Accuracy= 1.000\n",
            "Step 6000, Minibatch Loss= 0.0061, Training Accuracy= 1.000\n",
            "Step 6200, Minibatch Loss= 0.0092, Training Accuracy= 0.996\n",
            "Step 6400, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
            "Step 6600, Minibatch Loss= 0.0040, Training Accuracy= 1.000\n",
            "Step 6800, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
            "Step 7000, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
            "Step 7200, Minibatch Loss= 0.0160, Training Accuracy= 0.988\n",
            "Step 7400, Minibatch Loss= 0.0025, Training Accuracy= 1.000\n",
            "Step 7600, Minibatch Loss= 0.0216, Training Accuracy= 0.996\n",
            "Step 7800, Minibatch Loss= 0.0030, Training Accuracy= 1.000\n",
            "Step 8000, Minibatch Loss= 0.0034, Training Accuracy= 1.000\n",
            "Step 8200, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
            "Step 8400, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
            "Step 8600, Minibatch Loss= 0.0028, Training Accuracy= 1.000\n",
            "Step 8800, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
            "Step 9000, Minibatch Loss= 0.0023, Training Accuracy= 1.000\n",
            "Step 9200, Minibatch Loss= 0.0158, Training Accuracy= 0.996\n",
            "Step 9400, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
            "Step 9600, Minibatch Loss= 0.0179, Training Accuracy= 0.988\n",
            "Step 9800, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
            "Step 10000, Minibatch Loss= 0.0018, Training Accuracy= 1.000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.984375\n"
          ]
        }
      ],
      "source": [
        "# Start training\n",
        "import time\n",
        "  \n",
        "# store starting time\n",
        "begin = time.time()\n",
        "  \n",
        "loss_array = np.array([]);\n",
        "accuracy_array = np.array([]);\n",
        "with tf.Session() as sess:\n",
        "  \n",
        "    # Run the initializer\n",
        "  sess.run(init)\n",
        "\n",
        "  for step in range(1, training_steps+1):\n",
        "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "        # Reshape data to get 28 seq of 28 elements\n",
        "    batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
        "  \n",
        "        # Run optimization op (backprop)\n",
        "    sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "    if step % display_step == 0 or step == 1:\n",
        "      loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "      loss_array = np.append(loss_array,loss)\n",
        "      accuracy_array = np.append(accuracy_array,acc)\n",
        "      print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
        "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
        "                  \"{:.3f}\".format(acc))\n",
        "  time.sleep(1)\n",
        "# store end time\n",
        "  end = time.time()\n",
        "  time_taken = end-begin\n",
        "  print(\"Optimization Finished!\")\n",
        "\n",
        "  # Calculate accuracy for 128 mnist test images\n",
        "  test_len = 128\n",
        "  test_data = mnist.test.images[:test_len].reshape((-1, timesteps, num_input))\n",
        "  test_label = mnist.test.labels[:test_len]\n",
        "  print(\"Testing Accuracy:\",sess.run(accuracy, feed_dict={X: test_data, Y: test_label}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fPv1Mr01X5BG"
      },
      "outputs": [],
      "source": [
        "np.savetxt(\"tf.contrib.rnn.LSTMBlockCell_loss.csv\", loss_array, delimiter=\",\")\n",
        "np.savetxt(\"tf.contrib.rnn.LSTMBlockCell_acc.csv\", accuracy_array, delimiter=\",\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_taken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsmMpLAjyRIC",
        "outputId": "239986fb-5d88-4bdc-c51c-1b708263cd72"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71.71114349365234"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.savetxt(\"tf.contrib.rnn.LSTMBlockCell_time.csv\", [time_taken], delimiter=\",\")"
      ],
      "metadata": {
        "id": "Lq4jktnC1RWS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8hy7Moan3Fqc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "name": "rnn.BasicLSTMCell.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}