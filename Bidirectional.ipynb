{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bidirectional.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb2RTjFZoq6r",
        "outputId": "e18546a0-30e6-4f42-9264-52532533ad70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==1.13.1\n",
            "  Downloading tensorflow-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (92.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 92.6 MB 64 kB/s \n",
            "\u001b[?25hCollecting tensorboard<1.14.0,>=1.13.0\n",
            "  Downloading tensorboard-1.13.1-py3-none-any.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 47.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.19.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "  Downloading tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367 kB)\n",
            "\u001b[K     |████████████████████████████████| 367 kB 47.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.0.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.4.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.37.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (3.17.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.43.0)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.7.0)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.13.1) (1.5.2)\n",
            "Installing collected packages: mock, tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.13.1 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-applications-1.0.8 mock-4.0.3 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install tensorflow==1.13.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib import rnn\n",
        "import numpy as np\n",
        "# Import MNIST data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uWfrfcbo0j1",
        "outputId": "3989c80b-8b58-4b78-9d8d-a7c199a5d05a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-888e348dc073>:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Parameters\n",
        "learning_rate = 0.001\n",
        "training_steps = 10000\n",
        "batch_size = 128\n",
        "display_step = 200\n",
        "\n",
        "# Network Parameters\n",
        "num_input = 28 # MNIST data input (img shape: 28*28)\n",
        "timesteps = 28 # timesteps\n",
        "num_hidden = 128 # hidden layer num of features\n",
        "num_classes = 10 # MNIST total classes (0-9 digits)\n",
        "\n",
        "# tf Graph input\n",
        "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
        "Y = tf.placeholder(\"float\", [None, num_classes])"
      ],
      "metadata": {
        "id": "idv7B1fPo5De"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define weights\n",
        "weights = {\n",
        "    # Hidden layer weights => 2*n_hidden because of forward + backward cells\n",
        "    'out': tf.Variable(tf.random_normal([2*num_hidden, num_classes]))\n",
        "}\n",
        "biases = {\n",
        "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AurXJp21o7V6",
        "outputId": "1091964d-2aad-491e-fd49-1499e775ce73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def BiRNN(x, weights, biases):\n",
        "    # Prepare data shape to match `rnn` function requirements\n",
        "    # Current data input shape: (batch_size, timesteps, n_input)\n",
        "    # Required shape: 'timesteps' tensors list of shape (batch_size, num_input)\n",
        "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, num_input)\n",
        "    x = tf.unstack(x, timesteps, 1)\n",
        "    # Define lstm cells with tensorflow\n",
        "    # Forward direction cell\n",
        "    lstm_fw_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
        "    # Backward direction cell\n",
        "    lstm_bw_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
        "    # Get lstm cell output\n",
        "    try:\n",
        "        outputs, _, _ = rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,\n",
        "                                              dtype=tf.float32)\n",
        "    except Exception: # Old TensorFlow version only returns outputs not states\n",
        "        outputs = rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,\n",
        "                                        dtype=tf.float32)\n",
        "    # Linear activation, using rnn inner loop last output\n",
        "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n"
      ],
      "metadata": {
        "id": "NnTGR_qro-7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits = BiRNN(X, weights, biases)\n",
        "prediction = tf.nn.softmax(logits)\n",
        "\n",
        "# Define loss and optimizer\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
        "    logits=logits, labels=Y))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "# Evaluate model (with test logits, for dropout to be disabled)\n",
        "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# Initialize the variables (i.e. assign their default value)\n",
        "init = tf.global_variables_initializer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_gVf0FGpBmo",
        "outputId": "467b0199-9afd-4512-e281-7c89b51a4e53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-5-9399e00d2c53>:12: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-5-9399e00d2c53>:19: static_bidirectional_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell, unroll=True))`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py:1565: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From <ipython-input-6-d6d6107040d4>:6: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    # Run the initializer\n",
        "    sess.run(init)\n",
        "\n",
        "    for step in range(1, training_steps+1):\n",
        "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "        # Reshape data to get 28 seq of 28 elements\n",
        "        batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
        "        # Run optimization op (backprop)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % display_step == 0 or step == 1:\n",
        "            # Calculate batch loss and accuracy\n",
        "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
        "                                                                 Y: batch_y})\n",
        "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \"{:.3f}\".format(acc))\n",
        "\n",
        "    print(\"Optimization Finished!\")\n",
        "\n",
        "    # Calculate accuracy for 128 mnist test images\n",
        "    test_len = 128\n",
        "    test_data = mnist.test.images[:test_len].reshape((-1, timesteps, num_input))\n",
        "    test_label = mnist.test.labels[:test_len]\n",
        "    print(\"Testing Accuracy:\",sess.run(accuracy, feed_dict={X: test_data, Y: test_label}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmNqJdokpBud",
        "outputId": "027df962-8110-4a05-e52e-9811fe3daa55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1, Minibatch Loss= 2.8882, Training Accuracy= 0.070\n",
            "Step 200, Minibatch Loss= 2.1047, Training Accuracy= 0.297\n",
            "Step 400, Minibatch Loss= 1.8547, Training Accuracy= 0.438\n",
            "Step 600, Minibatch Loss= 1.6416, Training Accuracy= 0.508\n",
            "Step 800, Minibatch Loss= 1.7067, Training Accuracy= 0.453\n",
            "Step 1000, Minibatch Loss= 1.5851, Training Accuracy= 0.508\n",
            "Step 1200, Minibatch Loss= 1.5198, Training Accuracy= 0.539\n",
            "Step 1400, Minibatch Loss= 1.4171, Training Accuracy= 0.539\n",
            "Step 1600, Minibatch Loss= 1.3379, Training Accuracy= 0.602\n",
            "Step 1800, Minibatch Loss= 1.2409, Training Accuracy= 0.641\n",
            "Step 2000, Minibatch Loss= 1.2109, Training Accuracy= 0.633\n",
            "Step 2200, Minibatch Loss= 1.1245, Training Accuracy= 0.648\n",
            "Step 2400, Minibatch Loss= 1.1525, Training Accuracy= 0.594\n",
            "Step 2600, Minibatch Loss= 1.0726, Training Accuracy= 0.656\n",
            "Step 2800, Minibatch Loss= 1.1418, Training Accuracy= 0.625\n",
            "Step 3000, Minibatch Loss= 1.0096, Training Accuracy= 0.688\n",
            "Step 3200, Minibatch Loss= 0.9352, Training Accuracy= 0.711\n",
            "Step 3400, Minibatch Loss= 0.9304, Training Accuracy= 0.742\n",
            "Step 3600, Minibatch Loss= 0.9364, Training Accuracy= 0.734\n",
            "Step 3800, Minibatch Loss= 1.0102, Training Accuracy= 0.656\n",
            "Step 4000, Minibatch Loss= 0.9957, Training Accuracy= 0.672\n",
            "Step 4200, Minibatch Loss= 0.8342, Training Accuracy= 0.742\n",
            "Step 4400, Minibatch Loss= 0.9684, Training Accuracy= 0.695\n",
            "Step 4600, Minibatch Loss= 0.7990, Training Accuracy= 0.766\n",
            "Step 4800, Minibatch Loss= 0.8587, Training Accuracy= 0.773\n",
            "Step 5000, Minibatch Loss= 0.7156, Training Accuracy= 0.805\n",
            "Step 5200, Minibatch Loss= 0.7745, Training Accuracy= 0.781\n",
            "Step 5400, Minibatch Loss= 0.8029, Training Accuracy= 0.703\n",
            "Step 5600, Minibatch Loss= 0.7834, Training Accuracy= 0.781\n",
            "Step 5800, Minibatch Loss= 0.7329, Training Accuracy= 0.766\n",
            "Step 6000, Minibatch Loss= 0.7170, Training Accuracy= 0.797\n",
            "Step 6200, Minibatch Loss= 0.6276, Training Accuracy= 0.797\n",
            "Step 6400, Minibatch Loss= 0.5700, Training Accuracy= 0.844\n",
            "Step 6600, Minibatch Loss= 0.6813, Training Accuracy= 0.758\n",
            "Step 6800, Minibatch Loss= 0.6195, Training Accuracy= 0.805\n",
            "Step 7000, Minibatch Loss= 0.5645, Training Accuracy= 0.875\n",
            "Step 7200, Minibatch Loss= 0.6534, Training Accuracy= 0.766\n",
            "Step 7400, Minibatch Loss= 0.7290, Training Accuracy= 0.789\n",
            "Step 7600, Minibatch Loss= 0.7821, Training Accuracy= 0.742\n",
            "Step 7800, Minibatch Loss= 0.5292, Training Accuracy= 0.812\n",
            "Step 8000, Minibatch Loss= 0.5599, Training Accuracy= 0.812\n",
            "Step 8200, Minibatch Loss= 0.6107, Training Accuracy= 0.773\n",
            "Step 8400, Minibatch Loss= 0.5885, Training Accuracy= 0.812\n",
            "Step 8600, Minibatch Loss= 0.5565, Training Accuracy= 0.859\n",
            "Step 8800, Minibatch Loss= 0.5365, Training Accuracy= 0.836\n",
            "Step 9000, Minibatch Loss= 0.4919, Training Accuracy= 0.820\n",
            "Step 9200, Minibatch Loss= 0.4938, Training Accuracy= 0.891\n",
            "Step 9400, Minibatch Loss= 0.5431, Training Accuracy= 0.812\n",
            "Step 9600, Minibatch Loss= 0.4028, Training Accuracy= 0.898\n",
            "Step 9800, Minibatch Loss= 0.4541, Training Accuracy= 0.875\n",
            "Step 10000, Minibatch Loss= 0.2879, Training Accuracy= 0.953\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.8984375\n"
          ]
        }
      ]
    }
  ]
}